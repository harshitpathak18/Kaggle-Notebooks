{"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":5179545,"sourceType":"datasetVersion","datasetId":3011225}],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# <div style=\"color:white; background:#E606DE; font-size:35px; padding:10px; margin:5px; border-radius:25px; text-align:center\">Alzheimer's Diagnosis with Deep Learning</div>","metadata":{}},{"cell_type":"markdown","source":"## <div style=\"color:white; background:#E606DE; font-size:30px; padding:10px; margin:5px; border-radius:25px; text-align:center\">Importing Dependencies</div>","metadata":{"id":"iCYjsKT9nUBS"}},{"cell_type":"code","source":"import os\nimport cv2\nimport random\nimport shutil\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom PIL import Image\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom skimage.io import imread\nimport matplotlib.pyplot as plt\nfrom matplotlib.image import imread\nfrom keras.models import Sequential\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.applications import VGG16\nfrom tensorflow.keras.preprocessing import image\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.layers import Dense, Flatten, Dropout, BatchNormalization","metadata":{"id":"46fK83U1xSNt","execution":{"iopub.status.busy":"2024-09-07T10:10:05.342862Z","iopub.execute_input":"2024-09-07T10:10:05.343801Z","iopub.status.idle":"2024-09-07T10:10:05.350725Z","shell.execute_reply.started":"2024-09-07T10:10:05.343758Z","shell.execute_reply":"2024-09-07T10:10:05.349570Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# defining training & testing data path\ntrain_data_path='/kaggle/input/best-alzheimer-mri-dataset-99-accuracy/Combined Dataset/train'\ntest_data_path='/kaggle/input/best-alzheimer-mri-dataset-99-accuracy/Combined Dataset/test'","metadata":{"id":"tX5GTRLexhgC","execution":{"iopub.status.busy":"2024-09-07T09:23:05.504508Z","iopub.execute_input":"2024-09-07T09:23:05.504784Z","iopub.status.idle":"2024-09-07T09:23:05.508909Z","shell.execute_reply.started":"2024-09-07T09:23:05.504755Z","shell.execute_reply":"2024-09-07T09:23:05.507881Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <div style=\"color:white; background:#E606DE; font-size:30px; padding:10px; margin:5px; border-radius:25px; text-align:center\">Visualizing MRI Images</div>","metadata":{"id":"z0TvFnaWnN_x"}},{"cell_type":"code","source":"# Load the images\nno_impairment = imread(train_data_path+\"/No Impairment\"+\"/NoImpairment (1).jpg\")\nmild_impairment = imread(train_data_path+\"/Mild Impairment\"+\"/MildImpairment (1).jpg\")\nmoderate_impairment = imread(train_data_path+\"/Moderate Impairment\"+\"/ModerateImpairment (1).jpg\")\nvery_mild_impairment = imread(train_data_path+\"/Very Mild Impairment\"+\"/VeryMildImpairment (1).jpg\")\n\n\n# Create subplots\nfig, axes = plt.subplots(1, 4, figsize=(20, 5))\n\naxes = axes.flatten()\n\naxes[0].imshow(no_impairment, cmap='gray')\naxes[0].set_title('No Impairment', fontsize=18)\naxes[0].axis('off')\n\naxes[1].imshow(mild_impairment, cmap='gray')\naxes[1].set_title('Mild Impairment', fontsize=18)\naxes[1].axis('off')\n\naxes[2].imshow(moderate_impairment, cmap='gray')\naxes[2].set_title('Moderate Impairment', fontsize=18)\naxes[2].axis('off')\n\naxes[3].imshow(very_mild_impairment, cmap='gray')\naxes[3].set_title('Very Mild Impairment', fontsize=18)\naxes[3].axis('off')\n\nplt.tight_layout()\nplt.show()","metadata":{"id":"OMeFOVQNlDfh","outputId":"68e40c4e-d3b8-4b85-e224-2b89dfcb2aaf","execution":{"iopub.status.busy":"2024-09-07T09:23:05.533979Z","iopub.execute_input":"2024-09-07T09:23:05.534261Z","iopub.status.idle":"2024-09-07T09:23:06.059005Z","shell.execute_reply.started":"2024-09-07T09:23:05.534231Z","shell.execute_reply":"2024-09-07T09:23:06.057895Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Data shape\nrandom_image=train_data_path+\"/No Impairment\"+\"/NoImpairment (1).jpg\"\nprint(\"Image Shape:\",cv2.imread(random_image).shape)","metadata":{"execution":{"iopub.status.busy":"2024-09-07T09:23:06.061095Z","iopub.execute_input":"2024-09-07T09:23:06.061549Z","iopub.status.idle":"2024-09-07T09:23:06.067891Z","shell.execute_reply.started":"2024-09-07T09:23:06.061501Z","shell.execute_reply":"2024-09-07T09:23:06.066874Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <div style=\"color:white; background:#E606DE; font-size:30px; padding:10px; margin:5px; border-radius:25px; text-align:center\">Data Preprocessing</div>","metadata":{"id":"gWHb6-bOnFj_"}},{"cell_type":"code","source":"def data_preprocessing(output_size, val_split=0.1):\n    # ImageDataGenerator for training with validation split\n    train_datagen = ImageDataGenerator(rescale=1./255,\n                                       zoom_range=0.2,\n                                       shear_range=0.2,\n                                       rotation_range=15,\n                                       fill_mode='nearest',\n                                       horizontal_flip=True,\n                                       validation_split=val_split)  \n\n    # Training data generator\n    training_set = train_datagen.flow_from_directory(train_data_path,\n                                                     target_size=(output_size, output_size),\n                                                     batch_size=32,\n                                                     class_mode='categorical',\n                                                     shuffle=True,\n                                                     subset='training')  \n\n    # Validation data generator\n    validation_set = train_datagen.flow_from_directory(train_data_path,\n                                                       target_size=(output_size, output_size),\n                                                       batch_size=32,\n                                                       class_mode='categorical',\n                                                       shuffle=True,\n                                                       subset='validation')  \n\n    return training_set, validation_set\n\n\n# Splitting Data\ntraining_set, validation_set = data_preprocessing(output_size=150, val_split=0.1)","metadata":{"execution":{"iopub.status.busy":"2024-09-07T10:55:14.692118Z","iopub.execute_input":"2024-09-07T10:55:14.692768Z","iopub.status.idle":"2024-09-07T10:55:15.235065Z","shell.execute_reply.started":"2024-09-07T10:55:14.692730Z","shell.execute_reply":"2024-09-07T10:55:15.234243Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Training & Validation data Size\nprint(\"Training set distribution:\", dict(pd.Series(training_set.classes).value_counts()))\nprint(\"\\nValidation set distribution:\", dict(pd.Series(validation_set.classes).value_counts()))","metadata":{"execution":{"iopub.status.busy":"2024-09-07T10:55:18.184547Z","iopub.execute_input":"2024-09-07T10:55:18.185006Z","iopub.status.idle":"2024-09-07T10:55:18.194004Z","shell.execute_reply.started":"2024-09-07T10:55:18.184962Z","shell.execute_reply":"2024-09-07T10:55:18.192632Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <div style=\"color:white; background:#E606DE; font-size:30px; padding:10px; margin:5px; border-radius:25px; text-align:center\">Training the Model</div>","metadata":{"id":"Lzz1UvfenJW9"}},{"cell_type":"code","source":"# Load the pre-trained VGG16 model (excluding the top layers) with weights from ImageNet\nvgg_base = VGG16(weights='imagenet', include_top=False, input_shape=(150, 150, 3))\n\n# Freeze the layers of VGG16 so that they are not trainable\nvgg_base.trainable = False\n\n# Initialize the Sequential model\nmodel = Sequential([\n    # VGG16 as the base feature extractor\n    vgg_base,\n\n    # Flatten the output of the VGG16 base\n    Flatten(),\n\n    # Fully Connected Layer 1\n    Dense(256, activation='relu'),\n    BatchNormalization(),\n    Dropout(0.5),\n\n    # Fully Connected Layer 2\n    Dense(128, activation='relu'),\n    BatchNormalization(),\n    Dropout(0.5),\n    \n\n    # Output Layer with Softmax Activation (for 4 classes)\n    Dense(4, activation='softmax')\n])\n\n# Compile the model\nmodel.compile(optimizer=Adam(learning_rate=0.0001),\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])\n\n# Display the model summary\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2024-09-07T12:57:13.335062Z","iopub.execute_input":"2024-09-07T12:57:13.335820Z","iopub.status.idle":"2024-09-07T12:57:13.626762Z","shell.execute_reply.started":"2024-09-07T12:57:13.335781Z","shell.execute_reply":"2024-09-07T12:57:13.625869Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Compiling the model\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])","metadata":{"id":"8TTCVP6jqiyr","execution":{"iopub.status.busy":"2024-09-07T12:57:14.114203Z","iopub.execute_input":"2024-09-07T12:57:14.114612Z","iopub.status.idle":"2024-09-07T12:57:14.123713Z","shell.execute_reply.started":"2024-09-07T12:57:14.114575Z","shell.execute_reply":"2024-09-07T12:57:14.122877Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Training the model\nhistory = model.fit(training_set, validation_data = validation_set, batch_size = 64, epochs= 50, verbose = 1)","metadata":{"id":"iy4nUvCpqpgt","outputId":"6d18b38f-d426-4145-8ec5-79d9132664bd","execution":{"iopub.status.busy":"2024-09-07T12:57:31.568870Z","iopub.execute_input":"2024-09-07T12:57:31.569263Z","iopub.status.idle":"2024-09-07T13:47:30.019284Z","shell.execute_reply.started":"2024-09-07T12:57:31.569226Z","shell.execute_reply":"2024-09-07T13:47:30.018250Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <div style=\"color:white; background:#E606DE; font-size:30px; padding:10px; margin:5px; border-radius:25px; text-align:center\">Evaluating Model Performance</div>","metadata":{"id":"0yP3hY0alJ6F"}},{"cell_type":"code","source":"# Model's Performance\nsns.set(style=\"whitegrid\")\nfig, axes = plt.subplots(nrows=1, ncols=2, figsize=(14, 5))\n\n# Plotting Loss\naxes[0].plot(history.history['loss'], color='#FF6347', label='Training Loss', linewidth=2)\naxes[0].plot(history.history['val_loss'], color='#4169E1', label='Validation Loss', linewidth=2, linestyle='--')\naxes[0].set_title('Model Loss', fontsize=16, weight='bold')\naxes[0].set_xlabel('Epochs', fontsize=12, weight='bold')\naxes[0].set_ylabel('Loss', fontsize=12, weight='bold')\naxes[0].legend(loc='upper right', fontsize=12)\naxes[0].spines['top'].set_visible(False)\naxes[0].spines['right'].set_visible(False)\n\n# Plotting Accuracy\naxes[1].plot(history.history['accuracy'], color='#FF6347', label='Training Accuracy', linewidth=2)\naxes[1].plot(history.history['val_accuracy'], color='#4169E1', label='Validation Accuracy', linewidth=2, linestyle='--')\naxes[1].set_title('Model Accuracy', fontsize=16, weight='bold')\naxes[1].set_xlabel('Epochs', fontsize=12, weight='bold')\naxes[1].set_ylabel('Accuracy', fontsize=12, weight='bold')\naxes[1].legend(loc='lower right', fontsize=12)\naxes[1].spines['top'].set_visible(False)\naxes[1].spines['right'].set_visible(False)\n\n\nplt.suptitle('Training and Validation Metrics', fontsize=18, weight='bold', color='#333')\nplt.tight_layout(rect=[0, 0, 1, 0.95])\nplt.show()","metadata":{"id":"JATbuDi7kdpT","outputId":"a9392df8-f278-44fd-ecda-4f72d2d11d76","execution":{"iopub.status.busy":"2024-09-07T13:47:30.021709Z","iopub.execute_input":"2024-09-07T13:47:30.022147Z","iopub.status.idle":"2024-09-07T13:47:30.748249Z","shell.execute_reply.started":"2024-09-07T13:47:30.022101Z","shell.execute_reply":"2024-09-07T13:47:30.747276Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluate model on the test set\ntest_datagen = ImageDataGenerator(rescale=1./255)\n\ntest_set = test_datagen.flow_from_directory(test_data_path,\n                                                 target_size=(150, 150),\n                                                 batch_size=32,\n                                                 class_mode='categorical',\n                                                 shuffle=True)  \n\ntest_loss, test_accuracy = model.evaluate(test_set, verbose=1)\n\n# Print the test accuracy\nprint(f\"Test Loss: {test_loss:.4f}\")\nprint(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")","metadata":{"execution":{"iopub.status.busy":"2024-09-07T13:47:30.749543Z","iopub.execute_input":"2024-09-07T13:47:30.749899Z","iopub.status.idle":"2024-09-07T13:47:34.278880Z","shell.execute_reply.started":"2024-09-07T13:47:30.749858Z","shell.execute_reply":"2024-09-07T13:47:34.277963Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <div style=\"color:white; background:#E606DE; font-size:30px; padding:10px; margin:5px; border-radius:25px; text-align:center\">Model Predictions</div>","metadata":{"id":"YT1pPGXCkQ4N"}},{"cell_type":"code","source":"# Function for making predictions\ndef prediction(img_path, class_labels):\n    img = image.load_img(img_path, target_size=(150, 150))\n    img_array = image.img_to_array(img)\n    img_array = np.expand_dims(img_array, axis=0)\n    img_array /= 255.0  \n\n    # Make the prediction\n    prediction = model.predict(img_array)\n\n    # Convert the prediction to class labels\n    predicted_class_index = np.argmax(prediction, axis=1)[0]\n    predicted_class = class_labels[predicted_class_index]\n\n    return predicted_class, prediction[0]","metadata":{"id":"rt6f_NpLlsFh","outputId":"c688b2ca-2f52-4f0e-a69b-e972377108cf","execution":{"iopub.status.busy":"2024-09-07T13:47:34.280718Z","iopub.execute_input":"2024-09-07T13:47:34.281052Z","iopub.status.idle":"2024-09-07T13:47:34.287172Z","shell.execute_reply.started":"2024-09-07T13:47:34.281018Z","shell.execute_reply":"2024-09-07T13:47:34.286124Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define the folder path and class labels\nfolder_path = \"/kaggle/input/best-alzheimer-mri-dataset-99-accuracy/Combined Dataset/test\"\nclass_labels = [\"Mild Impairment\", \"Moderate Impairment\", \"No Impairment\", \"Very Mild Impairment\"]\n\n# Prepare a list to store file paths and corresponding class names\nimage_paths = []\nclass_names = [\"Mild Impairment\", \"Moderate Impairment\", \"No Impairment\", \"Very Mild Impairment\"]\n\nfor class_name in class_names:\n    class_folder = os.path.join(folder_path, class_name)\n    image_files = os.listdir(class_folder)\n    selected_images = random.sample(image_files, 2)  # Randomly select 2 images\n    for img_file in selected_images:\n        image_paths.append((os.path.join(class_folder, img_file), class_name))\n\n        \nfig, axes = plt.subplots(2, 4, figsize=(16, 8))\naxes = axes.ravel()  \n\nfor i, (img_path, true_class) in enumerate(image_paths):\n    predicted_class, probabilities = prediction(img_path, class_labels)\n    img = plt.imread(img_path)\n    axes[i].imshow(img, cmap='gray')\n    axes[i].axis('off')\n    axes[i].set_title(f\"Pred: {predicted_class}\\nTrue: {true_class}\", fontsize=14)\n\nplt.tight_layout()\nplt.show()","metadata":{"id":"9LybJyJkMD_D","execution":{"iopub.status.busy":"2024-09-07T13:47:34.288768Z","iopub.execute_input":"2024-09-07T13:47:34.289092Z","iopub.status.idle":"2024-09-07T13:47:36.912878Z","shell.execute_reply.started":"2024-09-07T13:47:34.289061Z","shell.execute_reply":"2024-09-07T13:47:36.911969Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}